<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Suspicious Behavior Detection</title>
    <style>
        body { font-family: Arial, sans-serif; text-align: center; margin: 20px; }
        video { width: 100%; max-width: 640px; height: auto; border: 2px solid #000; }
        #output { margin-top: 20px; font-size: 18px; color: red; }
        canvas { display: none; }
        button { padding: 10px 20px; font-size: 16px; margin: 10px; }
    </style>
</head>
<body>
    <h1>AI Suspicious Behavior Detection</h1>
    <p>Accessing your phone's camera to detect suspicious behavior...</p>
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
    <div id="output">Loading AI model...</div>
    <button id="toggleBtn">Stop Detection</button>
    <button id="resetBtn">Reset Alert</button>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@latest"></script>
    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const output = document.getElementById('output');
        const toggleBtn = document.getElementById('toggleBtn');
        const resetBtn = document.getElementById('resetBtn');
        const ctx = canvas.getContext('2d');
        let isDetecting = true;
        let model;
        let prevObjects = [];
        let suspiciousState = false; // Persistent suspicious state
        let suspiciousMessage = 'No suspicious behavior detected.'; // Persistent message

        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: 'environment' }
                });
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    video.play();
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    loadModel();
                };
            } catch (err) {
                output.textContent = 'Error accessing camera: ' + err.message;
            }
        }

        async function loadModel() {
            try {
                model = await cocoSsd.load();
                output.textContent = 'AI model loaded. Detecting objects...';
                if (isDetecting) detectObjects();
            } catch (err) {
                output.textContent = 'Error loading model: ' + err.message;
            }
        }

        async function detectObjects() {
            if (!isDetecting) {
                output.textContent = 'Detection stopped.';
                return;
            }

            const predictions = await model.detect(video);
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            let currentObjects = [];

            predictions.forEach(prediction => {
                const [x, y, width, height] = prediction.bbox;
                const label = prediction.class;
                const score = prediction.score;

                ctx.beginPath();
                ctx.rect(x, y, width, height);
                ctx.lineWidth = 2;
                ctx.strokeStyle = 'green';
                ctx.fillStyle = 'green';
                ctx.stroke();
                ctx.fillText(`${label} (${Math.round(score * 100)}%)`, x, y > 10 ? y - 5 : 10);

                if (label !== 'person') currentObjects.push({ label, x, y, score });

                if (label === 'person' && score > 0.7) {
                    const nearbyObject = predictions.find(p => 
                        p.class !== 'person' && 
                        Math.abs(p.bbox[0] - x) < 100 && 
                        Math.abs(p.bbox[1] - y) < 100 && 
                        p.score > 0.6
                    );
                    if (nearbyObject) {
                        ctx.strokeStyle = 'yellow';
                        ctx.strokeRect(x, y, width, height);
                    }
                }
            });

            // Check for pocketing only if not already suspicious
            if (!suspiciousState) {
                prevObjects.forEach(prev => {
                    const wasNearPerson = predictions.some(p => 
                        p.class === 'person' && 
                        Math.abs(p.bbox[0] - prev.x) < 100 && 
                        Math.abs(p.bbox[1] - prev.y) < 100
                    );
                    const stillVisible = currentObjects.some(curr => 
                        curr.label === prev.label && 
                        Math.abs(curr.x - prev.x) < 50 && 
                        Math.abs(curr.y - prev.y) < 50
                    );
                    if (wasNearPerson && !stillVisible) {
                        suspiciousState = true;
                        suspiciousMessage = `Suspicious: ${prev.label} may have been pocketed!`;
                    }
                });
            }

            prevObjects = currentObjects;

            // Display persistent message
            output.textContent = suspiciousState ? suspiciousMessage : 'No suspicious behavior detected.';
            output.style.color = suspiciousState ? 'red' : 'green';

            if (isDetecting) requestAnimationFrame(detectObjects);
        }

        toggleBtn.addEventListener('click', () => {
            isDetecting = !isDetecting;
            toggleBtn.textContent = isDetecting ? 'Stop Detection' : 'Start Detection';
            if (isDetecting && model) detectObjects();
        });

        resetBtn.addEventListener('click', () => {
            suspiciousState = false;
            suspiciousMessage = 'No suspicious behavior detected.';
            output.textContent = suspiciousMessage;
            output.style.color = 'green';
        });

        window.onload = startCamera;
    </script>
</body>
</html>